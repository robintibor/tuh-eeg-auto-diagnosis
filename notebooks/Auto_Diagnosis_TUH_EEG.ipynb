{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "import os\n",
    "import site\n",
    "os.sys.path.insert(0, '/home/schirrmr/braindecode/code/')\n",
    "os.sys.path.insert(0, '/home/schirrmr/braindecode/code/braindecode/')\n",
    "os.sys.path.insert(0, '/home/schirrmr/code/auto-diagnosis/')\n",
    "%cd /home/schirrmr/\n",
    "# switch to cpu\n",
    "os.environ['THEANO_FLAGS'] = 'floatX=float32,device=cpu,nvcc.fastmath=True'\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import cm\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'svg' \n",
    "matplotlib.rcParams['figure.figsize'] = (12.0, 1.0)\n",
    "matplotlib.rcParams['font.size'] = 7\n",
    "\n",
    "import matplotlib.lines as mlines\n",
    "import seaborn\n",
    "seaborn.set_style('darkgrid')\n",
    "import logging\n",
    "log = logging.getLogger()\n",
    "log.setLevel('DEBUG')\n",
    "import sys\n",
    "logging.basicConfig(format='%(asctime)s %(levelname)s : %(message)s',\n",
    "                     level=logging.DEBUG, stream=sys.stdout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "preproced_short_X = np.load('/home/schirrmr/code/auto-diagnosis/preproced-short-X.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "x = preproced_short_X[1]\n",
    "print(x.shape)\n",
    "import torch.nn.functional as F\n",
    "import torch as th\n",
    "from braindecode.torch_ext.util import np_to_var\n",
    "window_len = 25\n",
    "threshold = 10\n",
    "expected = 1\n",
    "cuda = True\n",
    "factor = np.float32(float(expected) / threshold) \n",
    "\n",
    "x_var = np_to_var([x])\n",
    "if cuda:\n",
    "    x_var = x_var.cuda()\n",
    "\n",
    "maxs = F.max_pool1d(x_var,window_len, stride=1)\n",
    "mins = F.max_pool1d(-x_var,window_len, stride=1)\n",
    "\n",
    "diffs = maxs + mins\n",
    "print(diffs.size())\n",
    "large_diffs = (diffs > threshold).type_as(diffs) * diffs\n",
    "padded = F.pad(large_diffs.unsqueeze(0), (window_len-1,window_len-1, 0,0), 'constant', 0)\n",
    "max_diffs = th.max(padded[:,:,:,window_len-1:], padded[:,:,:,:-window_len+1]).unsqueeze(0)\n",
    "\n",
    "x_var = x_var * (expected / max_diffs)\n",
    "x = x_var.data.cpu().numpy()\n",
    "print(padded.size())\n",
    "print(max_diffs.size())\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autoeeglukas.utils.my_io import (time_key, read_all_file_names,\n",
    "                                      get_recording_length, get_info_with_mne,\n",
    "                                      load_data_with_mne)\n",
    "from autoeeglukas.preprocessing.recording import Recording"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_file_names = read_all_file_names('/home/gemeinl/data/normal_abnormal/normalv1.1.0/v1.1.0/edf/train/normal/', '.edf',\n",
    "                    key='time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "abnormal_file_names = read_all_file_names('/home/gemeinl/data/normal_abnormal/abnormalv1.1.0/v1.1.0/edf/train/', '.edf',\n",
    "                    key='time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_file_names = normal_file_names + abnormal_file_names\n",
    "\n",
    "all_file_names = sorted(all_file_names,key=time_key)\n",
    "\n",
    "abnorm_counts = [fname.count('abnormal') for fname in all_file_names]\n",
    "assert set(abnorm_counts) == set([1,3])\n",
    "labels = np.array(abnorm_counts) == 3\n",
    "labels = labels.astype(np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#lengths = [get_recording_length(fname) for fname in all_file_names]\n",
    "\n",
    "#np.save('sorted-recording-lengths.npy', lengths)# then move somewhere\n",
    "\n",
    "#lengths = np.array(lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lengths = np.load('/home/schirrmr/code/auto-diagnosis/sorted-recording-lengths.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = lengths < 35 * 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_file_names = np.array(all_file_names)[mask]\n",
    "cleaned_labels = labels[mask]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### just for check what unclean labels are"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unclean_file_names = np.array(all_file_names)[~mask]\n",
    "\n",
    "unclean_abnorm_counts = [fname.count('abnormal') for fname in unclean_file_names]\n",
    "unclean_labels = np.array(unclean_abnorm_counts) == 3\n",
    "print(len(unclean_labels))\n",
    "print(np.mean(unclean_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "all_ch_names = [get_info_with_mne(fname)[4] for fname in all_file_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "all_fs = [get_info_with_mne(fname)[1] for fname in all_file_names]\n",
    "cleaned_fs = np.array(all_fs)[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd /home/schirrmr/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import resampy\n",
    "from braindecode.datautil.signalproc import exponential_running_standardize\n",
    "def load_data(fname, preproc_functions):\n",
    "    cnt, sfreq, n_samples, n_channels, chan_names, n_sec = get_info_with_mne(\n",
    "        fname)\n",
    "    log.info(\"Load data...\")\n",
    "    cnt.load_data()\n",
    "\n",
    "    wanted_elecs = ['A1', 'A2', 'C3', 'C4', 'CZ', 'F3', 'F4', 'F7', 'F8', 'FP1',\n",
    "                    'FP2', 'FZ', 'O1', 'O2',\n",
    "                    'P3', 'P4', 'PZ', 'T3', 'T4', 'T5', 'T6']\n",
    "\n",
    "    selected_ch_names = []\n",
    "    for wanted_part in wanted_elecs:\n",
    "        wanted_found_name = []\n",
    "        for ch_name in cnt.ch_names:\n",
    "            if ' ' + wanted_part + '-' in ch_name:\n",
    "                wanted_found_name.append(ch_name)\n",
    "        assert len(wanted_found_name) == 1\n",
    "        selected_ch_names.append(wanted_found_name[0])\n",
    "\n",
    "    cnt = cnt.pick_channels(selected_ch_names)\n",
    "\n",
    "    assert np.array_equal(cnt.ch_names, selected_ch_names)\n",
    "    data = (cnt.get_data() * 1e6).astype(np.float32)\n",
    "    fs = cnt.info['sfreq']\n",
    "    log.info(\"Preprocessing...\")\n",
    "    for fn in preproc_functions:\n",
    "        log.info(fn)\n",
    "        data, fs = fn(data, fs)\n",
    "        data = data.astype(np.float32)\n",
    "        fs = float(fs)\n",
    "    return data\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preproc_functions = []\n",
    "sampling_freq = 100\n",
    "sec_to_cut = 60\n",
    "preproc_functions.append(lambda data,fs: (data[:, int(sec_to_cut * fs):-int(\n",
    "        sec_to_cut * fs)], fs))\n",
    "preproc_functions.append(lambda data,fs: (np.clip(data,-800,800), fs))\n",
    "preproc_functions.append(lambda data, fs: (resampy.resample(data, fs,\n",
    "                                sampling_freq, axis=1, filter='kaiser_fast'), sampling_freq))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "n_recordings = 100\n",
    "X = [load_data(fname, preproc_functions) for fname in cleaned_file_names[:n_recordings]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.median([np.std(x) for x in X])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean([np.std(x) for x in X])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.median([np.mean(x) for x in X])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean([np.mean(x) for x in X])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot([np.var(x) for x, this_y in zip(X, cleaned_labels) if this_y== 0])\n",
    "plt.plot([np.var(x) for x, this_y in zip(X, cleaned_labels) if this_y== 1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [np.var(x) for x, this_y in zip(X, cleaned_labels) if this_y== 0]\n",
    "b = [np.var(x) for x, this_y in zip(X, cleaned_labels) if this_y== 1]\n",
    "print(np.median(a))\n",
    "print(np.median(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.mean(a))\n",
    "print(np.mean(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "n_recordings = None\n",
    "X = [load_data(fname, preproc_functions=[]) for fname in cleaned_file_names[:n_recordings]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_vals = [np.max(x) for x in X]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "min_vals = [np.min(x) for x in X]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stds =  [np.std(x) for x in X]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(stds)\n",
    "plt.figure()\n",
    "\n",
    "seaborn.distplot(stds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "means =  [np.mean(x) for x in X]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(means)\n",
    "plt.figure()\n",
    "\n",
    "seaborn.distplot(means)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stds_clean =  [np.std(np.clip(x,-800,800)) for x in X]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(stds_clean)\n",
    "plt.figure()\n",
    "\n",
    "seaborn.distplot(stds_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "means_clean =  [np.mean(np.clip(x,-800,800)) for x in X]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(means_clean)\n",
    "plt.figure()\n",
    "\n",
    "seaborn.distplot(means_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argmax(means_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "standardized = exponential_running_standardize(X[833].T,factor_new=0.001,init_block_size=100).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.max(standardized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "short_X = [x[:,fs*60:4*fs*60] for x, fs in zip(X, cleaned_fs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "apply preproc_functions to short X, also copy thme here maybe change max min to 800...\n",
    "compute max mean abs etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preproc_functions = []\n",
    "sampling_freq = 100\n",
    "preproc_functions.append(lambda data,fs: (np.clip(data,-800,800), fs))\n",
    "preproc_functions.append(lambda data, fs: (resampy.resample(data, fs,\n",
    "                                sampling_freq, axis=1, filter='kaiser_fast'), sampling_freq))\n",
    "preproc_functions.append(lambda data, fs: (exponential_running_standardize(\n",
    "    data.T,factor_new=0.001).T, fs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preproc_functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preproced_short_X = []\n",
    "\n",
    "for x, fs in zip(short_X, cleaned_fs):\n",
    "    log.info(\"Preprocess...\")\n",
    "    for fn in preproc_functions:\n",
    "        x, fs = fn(x, fs)\n",
    "        x = x.astype(np.float32)\n",
    "    preproced_short_X.append(x)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preproced_short_X = preproced_short_X[2::3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxes = [np.max(x) for x in preproced_short_X]\n",
    "plt.plot(maxes)\n",
    "plt.figure()\n",
    "seaborn.distplot(maxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mins = [np.min(x) for x in preproced_short_X]\n",
    "plt.plot(mins)\n",
    "plt.figure()\n",
    "seaborn.distplot(mins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.save('code/auto-diagnosis/preproced-short-X.npy', preproced_short_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argsort(maxes)[::-1][10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = preproced_short_X[276]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argmax(np.max(x, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = preproced_short_X[276]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxs = torch.nn.functional.max_pool1d(torch.autograd.Variable(\n",
    "    torch.from_numpy(np.array(preproced_short_X[276:277]))), 10, stride=1).data.cpu().numpy()\n",
    "mins = -torch.nn.functional.max_pool1d(torch.autograd.Variable(\n",
    "    torch.from_numpy(-np.array(preproced_short_X[276:277]))), 10, stride=1).data.cpu().numpy()\n",
    "                                   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diffs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diffs = maxs-mins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.max(diffs, axis=1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.flatnonzero(np.max(diffs, axis=1).squeeze() > 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# make to mask with 10 next ones also in mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x[:,17000:18000].T);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.maximum.accumulate(x, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.max(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x[:,17000:18000].T);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.plot(x[:,13840:13880].T);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = preproced_short_X[1739]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argmax(np.max(x, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x[:,13000:14000].T);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x[:,13840:13880].T);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x[:,7400:7450].T);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot([np.percentile(np.abs(x),99) for x in X])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seaborn.distplot(lengths[lengths < 35 * 60] / 60.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(X[0][:,:10000].T);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = cleaned_labels[:n_recordings]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "median_amps = []\n",
    "window_len = 100\n",
    "for x in X:\n",
    "    log.info(\"Compute FFT for recording...\")\n",
    "    this_bps = []\n",
    "    for i_start in range(0, x.shape[1]-100,100):\n",
    "        this_bps.append(np.abs(np.fft.rfft(x[:,i_start:i_start+100], axis=1)))\n",
    "    \n",
    "    median_amps.append(np.median(this_bps, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "median_amps = np.array(median_amps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X[0].dtype == 'float32'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.plot(np.mean(median_amps[y==0], axis=(0,1)).T);\n",
    "plt.plot(np.mean(median_amps[y==1], axis=(0,1)).T);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from braindecode.datautil.signal_target import SignalAndTarget\n",
    "from braindecode.datautil.splitters import split_into_two_sets\n",
    "\n",
    "train_set = SignalAndTarget(X[:60], y=y[:60])\n",
    "test_set = SignalAndTarget(X[60:], y=y[60:])\n",
    "\n",
    "train_set, valid_set = split_into_two_sets(train_set, first_set_fraction=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from braindecode.models.shallow_fbcsp import ShallowFBCSPNet\n",
    "from torch import nn\n",
    "from braindecode.torch_ext.util import set_random_seeds\n",
    "from braindecode.models.util import to_dense_prediction_model\n",
    "\n",
    "# Set if you want to use GPU\n",
    "# You can also use torch.cuda.is_available() to determine if cuda is available on your machine.\n",
    "cuda = True\n",
    "set_random_seeds(seed=20170629, cuda=cuda)\n",
    "\n",
    "# This will determine how many crops are processed in parallel\n",
    "input_time_length = 600\n",
    "n_classes = 2\n",
    "in_chans = train_set.X[0].shape[0]\n",
    "# final_conv_length determines the size of the receptive field of the ConvNet\n",
    "model = ShallowFBCSPNet(in_chans=in_chans, n_classes=n_classes, input_time_length=input_time_length,\n",
    "                        final_conv_length=20).create_network()\n",
    "to_dense_prediction_model(model)\n",
    "\n",
    "if cuda:\n",
    "    model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "\n",
    "optimizer = optim.Adam(model.parameters())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from braindecode.torch_ext.util import np_to_var\n",
    "# determine output size\n",
    "test_input = np_to_var(np.ones((2, in_chans, input_time_length, 1), dtype=np.float32))\n",
    "if cuda:\n",
    "    test_input = test_input.cuda()\n",
    "out = model(test_input)\n",
    "n_preds_per_input = out.cpu().data.numpy().shape[2]\n",
    "print(\"{:d} predictions per input/trial\".format(n_preds_per_input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from braindecode.experiments.experiment import Experiment\n",
    "from braindecode.datautil.iterators import CropsFromTrialsIterator\n",
    "from braindecode.experiments.monitors import RuntimeMonitor, LossMonitor, CroppedTrialMisclassMonitor, MisclassMonitor\n",
    "from braindecode.experiments.stopcriteria import MaxEpochs\n",
    "import torch.nn.functional as F\n",
    "import torch as th\n",
    "from braindecode.torch_ext.modules import Expression\n",
    "# Iterator is used to iterate over datasets both for training\n",
    "# and evaluation\n",
    "iterator = CropsFromTrialsIterator(batch_size=32,input_time_length=input_time_length,\n",
    "                                  n_preds_per_input=n_preds_per_input)\n",
    "\n",
    "# Loss function takes predictions as they come out of the network and the targets\n",
    "# and returns a loss\n",
    "loss_function = lambda preds, targets: F.nll_loss(th.mean(preds, dim=2)[:,:,0], targets)\n",
    "\n",
    "# Could be used to apply some constraint on the models, then should be object\n",
    "# with apply method that accepts a module\n",
    "model_constraint = None\n",
    "# Monitors log the training progress\n",
    "monitors = [LossMonitor(), MisclassMonitor(col_suffix='sample_misclass'),\n",
    "            CroppedTrialMisclassMonitor(input_time_length), RuntimeMonitor(),]\n",
    "# Stop criterion determines when the first stop happens\n",
    "stop_criterion = MaxEpochs(20)\n",
    "exp = Experiment(model, train_set, valid_set, test_set, iterator, loss_function, optimizer, model_constraint,\n",
    "          monitors, stop_criterion, remember_best_column='valid_misclass',\n",
    "          run_after_early_stop=True, batch_modifier=None, cuda=cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp.run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
